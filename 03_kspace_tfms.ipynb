{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"03_kspace_tfms.ipynb","provenance":[{"file_id":"1Sa_ebRVKC9ywRnLrmIHlQGiP7pSjt-LC","timestamp":1591986585689}],"collapsed_sections":[],"toc_visible":true},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"view-in-github","colab_type":"text"},"source":["<a href=\"https://colab.research.google.com/github/RGologorsky/fastmri/blob/master/01_kspace_tfms.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"]},{"cell_type":"markdown","metadata":{"id":"GhcmjtAuMFPH","colab_type":"text"},"source":["## Kspace tfms\n","\n","- Implemented kspace transforms with np and Pytorch tensors\n","- Testing in testing_01_kspace_tfms.ipynb."]},{"cell_type":"code","metadata":{"id":"tNHc0QCheK6T","colab_type":"code","colab":{}},"source":["[hobbit-hole](https://en.wikipedia.org/wiki/Hobbit#Lifestyle \"Hobbit lifestyles\")"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"pQyNnL5n5aov","colab_type":"text"},"source":["For real images, \n","- FFT of a purely real array (eg image) has conjugate symmetry: ```\n","fft2_result[a, b] = fft2_result[-a, -b].conj()\n","```\n","- So rfft2 ouputs the left half (plus one column) of fft2 to save space & memory\n","\n","- RFFT output could correspond to either an odd or even length signal.\n","- By default, irfft assumes an even output length.\n","- To avoid losing information, when doing inverse (irfft), given the correct length of the original input.\n","\n","Sources: \n","\n","- https://stackoverflow.com/questions/43001729/how-should-i-interpret-the-output-of-numpy-fft-rfft2\n","\n","- https://numpy.org/doc/stable/reference/generated/numpy.fft.irfft.html"]},{"cell_type":"code","metadata":{"id":"iH3eU94srYYo","colab_type":"code","colab":{}},"source":["class TensorTfmsBase():\n","  # Shift low frequencies to center\n","  ishift = partial(T.ifftshift, dim=(-3,-2))\n","  shift  = partial(T.fftshift,  dim=(-3,-2))\n","  \n","  # convert image to float tensor; real tensor into complex tensor\n","  def im2tn(im): return tensor(im).double()\n","  def real2complex(t): return torch.stack((t, torch.zeros(t.shape).double()), axis=-1)\n","\n","  # Decorators\n","  static_methods = [im2tn, real2complex]\n","  for f in static_methods: f = staticmethod(f)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"i31pLrHqsPWz","colab_type":"code","colab":{}},"source":["class MRTensorTfms(TensorTfmsBase):\n","  # FFT\n","  fft  = partial(torch.ifft, signal_ndim = 2, normalized=True)\n","  ifft = partial(torch.ifft, signal_ndim = 2, normalized=True)\n","\n","  # centered image to (centered) kspace (and back)\n","  def mr2k(cls): return [cls.ishift,  fft, cls.shift]\n","  def k2mr(cls): return [cls.ishift, ifft, cls.shift]\n","\n","  # Viz complex k in magnitude-only kspace (log)\n","  mgn  = [T.complex_abs]\n","  complex2log_mgn = mgn + [add(1e-9), torch.log, torch.abs]\n","\n","  # Decorators\n","  class_methods = [mr2k, k2mr]\n","  for f in class_methods: f = classmethod(f)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"OdCrN_Luv0ZX","colab_type":"code","colab":{}},"source":["class IMTensorTfms(TensorTfmsBase):\n","  # FFT (real)\n","  fft  = partial(torch.rfft,  signal_ndim = 2, normalized=True)\n","  ifft = partial(torch.irfft, signal_ndim = 2, normalized=True)\n","\n","  # uncentered image to (centered) kspace (and back)\n","  def im2k(cls): return [fft,   cls.shift]\n","  def k2im(cls): return [cls.ishift, ifft]\n","\n","    # Decorators\n","  class_methods = [im2k, k2im]\n","  for f in class_methods: f = classmethod(f)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"FtWdpSSOc4nO","colab_type":"code","colab":{}},"source":["# class TensorTfmsBase():\n","  \n","#   # FFT\n","#   fft  = partial(torch.ifft, signal_ndim = 2, normalized=True)\n","#   ifft = partial(torch.ifft, signal_ndim = 2, normalized=True)\n","\n","#   # Shift low frequencies to center\n","#   ishift = partial(T.ifftshift, dim=(-3,-2))\n","#   shift  = partial(T.fftshift,  dim=(-3,-2))\n","\n","#   # convert image to float tensor; real tensor into complex tensor\n","#   def im2tn(im): return tensor(im).double()\n","#   def real2complex(t): return torch.stack((t, torch.zeros(t.shape).double()), axis=-1)\n","\n","#   # centered image to (centered) kspace (and back)\n","#   def center_im2k(cls): return [cls.ishift, cls.fft, cls.shift]\n","#   def k2center_im(cls): return [cls.ishift, cls.ifft, cls.shift]\n","\n","#   # uncentered image to (centered) kspace (and back)\n","#   def uncentered_im2k(cls): return [cls.fft,   cls.shift]\n","#   def uncentered_k2im(cls): return [cls.ishift, cls.ifft]\n","\n","#   # Viz complex k in magnitude-only kspace (log)\n","#   mgn  = [T.complex_abs]\n","#   complex2log_mgn = mgn + [add(1e-9), torch.log, torch.abs]\n","\n","#   # Decorators\n","#   static_methods = [im2tn, real2complex]\n","#   class_methods  = [center_im2k, k2center_im, im2k, k2im]\n","\n","#   for f in static_methods: f = staticmethod(f)\n","#   for f in class_methods:  f = classmethod(f)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"kY8xd3f8Cr8P","colab_type":"code","colab":{}},"source":["# class MRTensorTfms(TensorTfmsBase):\n","#   # centered real image to centered kspace (and back)\n","#   def im2k(cls): return super().centered_im2k()     \n","#   def k2im(cls): return super().centered_k2im()\n","  \n","#   # decorators\n","#   for f in [im2k, k2im]: f = classmethod(f)\n","\n","# class RealImageTensorTfms(TensorTfmsBase):\n","#   fft  = partial(torch.rfft,  signal_ndim = 2, normalized=True)\n","#   ifft = partial(torch.irfft, signal_ndim = 2, normalized=True)\n","\n","#   # uncentered real image to centered kspace (and back)\n","#   @classmethod\n","#   def im2k(cls, onesided=True): \n","#     cls.fft = partial(fft, onesided=onesided)\n","#     return super().uncentered_im2k()\n","     \n","#   @classmethod\n","#   def k2im(cls, onesided=True, s=None):\n","#     cls.ifft =  partial(ifft, onesided=onesided, signal_sizes=s)\n","#     return super().uncentered_k2im()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"i8ueVDE0Cq6U","colab_type":"code","colab":{}},"source":["# class BatchShift():\n","#   # batch fft & ifft shift -- shift all but batch dimension\n","#   def ifftshift(x):\n","#     dim = tuple(range(x.dim()))[1:]\n","#     shift = [(dim + 1) // 2 for dim in x.shape[1:]]\n","#     return T.roll(x, shift, dim)\n","\n","#   def fftshift(x):\n","#     dim = tuple(range(x.dim()))[1:]\n","#     shift = [dim // 2 for dim in x.shape[1:]]\n","#     return T.roll(x, shift, dim)\n","\n","# class BatchTensorTfms(TensorTfms, BatchShift): pass\n","# class BatchRealTensorTfms(RealTensorTfms, BatchShift): pass"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"vpzTQ4TzbS46","colab_type":"code","colab":{}},"source":["def apply(data, tfms, pre=None, post=None): return Pipeline(L(pre) + L(tfms) + L(post))(data)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"FyIbaRXhhWQT","colab_type":"text"},"source":["## Viz: function to plot images"]},{"cell_type":"code","metadata":{"id":"UlD5FyNoha2T","colab_type":"code","colab":{}},"source":["def idx(lst,i, default=None): return lst[i] if i < len(lst) else default"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"YQ5MxTTMYWrZ","colab_type":"code","colab":{}},"source":["def plot(imgs, titles=[None], cmaps=[\"gray\"], nrows=1, ncols=1, figsize = (6,6), **kwargs):\n","\n","   # listify so we input can be string instead of 1-item list\n","  imgs, titles, cmaps = L(imgs), L(titles), L(cmaps)\n","\n","  # default set nrows, ncols = 1, len(imgs)\n","  if nrows * ncols != len(imgs): nrows, ncols = 1, len(imgs)\n","\n","  # default repeat cmap until same size as images\n","  cmaps = cmaps * int(len(imgs)/len(cmaps))\n","\n","  fig,axes = plt.subplots(nrows, ncols, figsize=figsize, squeeze=False)\n","  axes = axes.flatten()\n","  for i,im in enumerate(imgs): \n","    axes[i].imshow(im, cmap=idx(cmaps,i))\n","    axes[i].set_xticklabels([]), axes[i].set_yticklabels([])\n","    axes[i].set_title(idx(titles,i))\n","    axes[i].set_xlabel(im.shape)\n","  fig.tight_layout()\n","  fig.show()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"HZQCqUPw3q9n","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"zWqdogDG3njV","colab_type":"text"},"source":["# Common KSpace Transforms"]},{"cell_type":"code","metadata":{"id":"QbRrs6P-ku2d","colab_type":"code","colab":{}},"source":["# permute kspace tensor: N1HW(Complex) to N(Complex)HW\n","class Complex2Channel(Transform):\n","  order = 99 # happens after complex k\n","\n","  # N1HW(Complex) -> N(Complex)HW\n","  def encodes(self, t:Tensor):\n","    if t.size(-1) == 2: return torch.squeeze(t.transpose(-1,-2).transpose(-2,-3))\n","    return t\n","\n","  # NCHW -> NHWC\n","  def decodes(self, t:Tensor):\n","    if t.size(-3) == 2: return t.transpose(-3,-2).transpose(-2,-1)\n","    return t\n","    \n","# shows concat real & kspace into one image\n","class ShowK(Tuple):\n","  def show(self, ctx=None, **kwargs): \n","    k,real = self\n","    line = k.new_zeros(k.shape[0], 10)\n","    return show_image(torch.cat([k,line,real], dim=1), title = \"K & Real\", ctx=ctx, **kwargs)\n","\n","# take dataset item (real img, category), convert to (k arr, category)\n","class BatchReal2ComplexK(Transform):\n","  order = 50 # needs to run after save shape\n","\n","  # do nothing to tensor categories\n","  def encodes(self, t:TensorCategory): return t\n","  def decodes(self, t:TensorCategory): return t\n","\n","  def encodes(self, t:Tensor): return apply(t, TensorTfms.batch_real2k(onesided=False))\n","\n","\n","  def decodes(self, t_k:Tensor):\n","    t_k_abs         = apply(t_k, TensorTfms.t_abs)\n","    t_k_log_abs     = apply(t_k_abs, TensorTfms.log_abs)\n","\n","    t_real     = apply(t_k, TensorTfms.batch_k2real(onesided=False))\n","    \n","    return ShowK(t_k_log_abs, t_real)\n","\n","# converts complex k-space (2channel) to amplitude k-space (1channel)\n","class ComplexK2LogAbs(Transform):\n","  order = 51 # needs to run after Real2ComplexK\n","\n","  # do nothing to tensor categories\n","  def encodes(self, t:TensorCategory): return t\n","  def decodes(self, t:TensorCategory): return t\n","\n","  def encodes(self, t:Tensor): return apply(t, TensorTfms.log_abs, pre=TensorTfms.t_abs)"],"execution_count":0,"outputs":[]}]}